This directory contains a sample matrix multiplication code in matmul.cu.

Two GPU-equipped nodes have been reserved for class use. These are: 

c22n05 and c22n06

Each node contains 4 GK210 GPUs (actually, 2 K80 GPUs, each of which contains 2 GK210 GPUs).
In addition, each node contains 20 cores and 128 GB of CPU memory. 

You will be able to run jobs on 1 GPU at a time, and we ask you to submit only 1 job at a time.
To access a GPU you must submit a job to the cpsc424_gpu partition using the following Slurm srun
command (for an interactive session, which is probably what you will want to use for this assignment).
may well be what you will want to use throughout this assignment). The srun command below
illustrates the maximum settings; you may reduce some or all if you wish.

srun --pty -c 5 --mem-per-cpu=6100 -p cpsc424_gpu --gres-flags=enforce-binding -t 2:00:00 --gres=gpu:1 bash

You may add --x11 to this if you wish. While the example shows a 2-hour time limit, 
please use shorter durations when possible so that everyone gets a fair chance to access the GPU nodes.

For a batch job, you can create a script using similar options and submit it using sbatch. (Of course,
you won't want to use --pty or "bash".

From here on in this document, you must be in a session on one of the GPU
nodes. Most GPU-related commands will not work on nodes that have no GPUs.

NOTE: For this assignment, we will use the Gnu gcc compiler for non-CUDA code, since our
installations of CUDA are not set up for the Intel icc compiler. 

=============================================================================

Once you've logged into a GPU node and allocated a GPU (all done with the srun command), you're ready to go. 

Start by loading two module files:

   module load GCC CUDA

This will set your PATH and LD_LIBRARY_PATH environment variables to find 
the gcc compilers and the Cuda tools and libraries.

After loading the module files, try running "nvidia-smi" to learn more about
the GPU assigned to you. NOTE: Neither this command, nor the Makefile I've
provided will work on non-GPU nodes. Note that your GPU will say that it is a K80,
but it is really only half of a K80 (that is, a GK210 GPU).

You may also find it illuminating to run:

/gpfs/loomis/apps/avx/software/CUDA/10.1.105/extras/demo_suite/deviceQuery

This command will give you more information about specs and limitations of the GK210 GPU.

=============================================================================

To build the sample matrix multiplication code, run

   make matmul

This make command uses the makefile Makefile, which invokes the nvcc compiler 
to build the code. 

Once the code is built, you can execute it using:

                      ./matmul <n> <B> <G>

where 

     <n> is the number of rows and columns in the (square) matrices

     <B> is the number of thread rows and columns in each (2-D) thread block. 

     <G> is the number of block rows and columns in the (2-D) kernel grid.

So this means that the code will set 

     blockDim.x = blockDim.y = <B>
     blockDim.z = 1

and

     gridDim.x = gridDim.y = <G>
     gridDim.z = 1

For the sample code, you need to have a total of at least <n> threads in both the x and y 
directions since each thread in the sample code computes just one entry of the output matrix.
(You could have excess blocks, if you wish, though there's no good reason for that.) 
The sample code checks to make sure that it has a sufficient number of threads
in the x and y directions to carry out the computation. You may need to modify
that check for later parts of the assignment.
